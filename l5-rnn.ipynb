{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 \n",
    "Попробуйте изменить параметры нейронной сети, работающей с датасетом imdb, либо нейронной сети, работающей airline-passengers (она прилагается вместе с датасетом к уроку в виде отдельного скрипта) так, чтобы улучшить её точность. Приложите анализ\n",
    "\n",
    "\n",
    "# 2\n",
    "Предложите свои варианты решения проблемы исчезающего градиента в RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2\n",
    "Для решения проблемы исчезающего градиента в rnn можно в качестве функции активации на пропускающих воротах взять relu вместо sigma так же можно следущее за ним операцию умножения заменить на сложении более подробно описано https://arxiv.org/abs/2308.05629\n",
    "Данное использование в отличие от lSTM и GRU менее операционно затратно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:01:01.718249Z",
     "iopub.status.busy": "2023-11-22T09:01:01.717235Z",
     "iopub.status.idle": "2023-11-22T09:01:01.724982Z",
     "shell.execute_reply": "2023-11-22T09:01:01.723791Z",
     "shell.execute_reply.started": "2023-11-22T09:01:01.718208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29 µs, sys: 5 µs, total: 34 µs\n",
      "Wall time: 39.1 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb\n",
    "from keras.utils import pad_sequences\n",
    "from keras.layers import Dropout, BatchNormalization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вариант по умолчанию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:02:16.230843Z",
     "iopub.status.busy": "2023-11-22T09:02:16.229957Z",
     "iopub.status.idle": "2023-11-22T09:15:34.321663Z",
     "shell.execute_reply": "2023-11-22T09:15:34.320707Z",
     "shell.execute_reply.started": "2023-11-22T09:02:16.230806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n",
      "25000 тренировочные последовательности\n",
      "25000 тестовые последовательности\n",
      "Pad последовательности (примеров в x единицу времени)\n",
      "x_train shape: (25000, 100)\n",
      "x_test shape: (25000, 100)\n",
      "Построение модели...\n",
      "Процесс обучения...\n",
      "Epoch 1/10\n",
      "196/196 [==============================] - 104s 480ms/step - loss: 0.5884 - accuracy: 0.6757 - val_loss: 0.3852 - val_accuracy: 0.8264\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 81s 413ms/step - loss: 0.3999 - accuracy: 0.8355 - val_loss: 0.4639 - val_accuracy: 0.7989\n",
      "Epoch 3/10\n",
      "196/196 [==============================] - 78s 398ms/step - loss: 0.3356 - accuracy: 0.8646 - val_loss: 0.3488 - val_accuracy: 0.8476\n",
      "Epoch 4/10\n",
      "196/196 [==============================] - 76s 389ms/step - loss: 0.2986 - accuracy: 0.8833 - val_loss: 0.3981 - val_accuracy: 0.8428\n",
      "Epoch 5/10\n",
      "196/196 [==============================] - 75s 382ms/step - loss: 0.2720 - accuracy: 0.8967 - val_loss: 0.3481 - val_accuracy: 0.8525\n",
      "Epoch 6/10\n",
      "196/196 [==============================] - 74s 380ms/step - loss: 0.2550 - accuracy: 0.9033 - val_loss: 0.5029 - val_accuracy: 0.8420\n",
      "Epoch 7/10\n",
      "196/196 [==============================] - 74s 378ms/step - loss: 0.2367 - accuracy: 0.9118 - val_loss: 0.4619 - val_accuracy: 0.8291\n",
      "Epoch 8/10\n",
      "196/196 [==============================] - 75s 383ms/step - loss: 0.2131 - accuracy: 0.9214 - val_loss: 0.3792 - val_accuracy: 0.8458\n",
      "Epoch 9/10\n",
      "196/196 [==============================] - 74s 376ms/step - loss: 0.1968 - accuracy: 0.9284 - val_loss: 0.7370 - val_accuracy: 0.8101\n",
      "Epoch 10/10\n",
      "196/196 [==============================] - 75s 383ms/step - loss: 0.1818 - accuracy: 0.9338 - val_loss: 0.4455 - val_accuracy: 0.8362\n",
      "196/196 [==============================] - 5s 28ms/step - loss: 0.4455 - accuracy: 0.8362\n",
      "Результат при тестировании: 0.44548922777175903\n",
      "Тестовая точность: 0.8361999988555908\n",
      "CPU times: user 25min 21s, sys: 3min 4s, total: 28min 25s\n",
      "Wall time: 13min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_features = 10000\n",
    "\n",
    "# обрезание текстов после данного количества слов (среди top max_features наиболее используемые слова)\n",
    "maxlen = 100\n",
    "batch_size = 128 # увеличьте значение для ускорения обучения\n",
    "\n",
    "\n",
    "from keras.backend import dropout\n",
    "def train_nn_1():\n",
    "    print('Загрузка данных...')\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "    print(len(x_train), 'тренировочные последовательности')\n",
    "    print(len(x_test), 'тестовые последовательности')\n",
    "  \n",
    "    print('Pad последовательности (примеров в x единицу времени)')\n",
    "    x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "    x_test = pad_sequences(x_test, maxlen=maxlen)\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print('x_test shape:', x_test.shape)\n",
    "  \n",
    "    print('Построение модели...')\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 128))\n",
    "    model.add(LSTM(128, dropout=0.4, recurrent_dropout=0.4))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(32, activation='LeakyReLU'))            # New line\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(16, activation='elu'))\n",
    "    model.add(Dropout(0.2))                                  # New line\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "  \n",
    "    # стоит попробовать использовать другие оптимайзер и другие конфигурации оптимайзеров\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='RMSprop', # при использовании этого оптимайзера модель показывает наилучшие результаты.\n",
    "                  metrics=['accuracy'])\n",
    "    callbacks = [keras.callbacks.ModelCheckpoint(\"fraud_model_at_epoch_{epoch}.h5\")]\n",
    "    print('Процесс обучения...')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=10, # увеличьте при необходимости\n",
    "              callbacks = callbacks,\n",
    "              validation_data=(x_test, y_test))\n",
    "    score, acc = model.evaluate(x_test, y_test,\n",
    "                                batch_size=batch_size)\n",
    "    print('Результат при тестировании:', score)\n",
    "    print('Тестовая точность:', acc)\n",
    "train_nn_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Увеличим количество эпох \n",
    "## Добавим нормализацию после ккаждого слоя и увеличим dropout для уменьшения переобучения "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:30:01.321716Z",
     "iopub.status.busy": "2023-11-22T09:30:01.321334Z",
     "iopub.status.idle": "2023-11-22T09:45:10.544554Z",
     "shell.execute_reply": "2023-11-22T09:45:10.543656Z",
     "shell.execute_reply.started": "2023-11-22T09:30:01.321684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n",
      "25000 тренировочные последовательности\n",
      "25000 тестовые последовательности\n",
      "Pad последовательности (примеров в x единицу времени)\n",
      "x_train shape: (25000, 100)\n",
      "x_test shape: (25000, 100)\n",
      "Построение модели...\n",
      "Процесс обучения...\n",
      "Epoch 1/15\n",
      "149/149 [==============================] - 79s 495ms/step - loss: 0.5527 - accuracy: 0.7070 - val_loss: 0.6433 - val_accuracy: 0.5243\n",
      "Epoch 2/15\n",
      "149/149 [==============================] - 66s 445ms/step - loss: 0.3666 - accuracy: 0.8468 - val_loss: 0.4629 - val_accuracy: 0.8117\n",
      "Epoch 3/15\n",
      "149/149 [==============================] - 63s 424ms/step - loss: 0.3199 - accuracy: 0.8683 - val_loss: 0.3655 - val_accuracy: 0.8354\n",
      "Epoch 4/15\n",
      "149/149 [==============================] - 60s 400ms/step - loss: 0.2889 - accuracy: 0.8841 - val_loss: 0.3747 - val_accuracy: 0.8277\n",
      "Epoch 5/15\n",
      "149/149 [==============================] - 59s 396ms/step - loss: 0.2617 - accuracy: 0.8978 - val_loss: 0.3409 - val_accuracy: 0.8502\n",
      "Epoch 6/15\n",
      "149/149 [==============================] - 58s 389ms/step - loss: 0.2427 - accuracy: 0.9064 - val_loss: 0.3532 - val_accuracy: 0.8528\n",
      "Epoch 7/15\n",
      "149/149 [==============================] - 57s 385ms/step - loss: 0.2277 - accuracy: 0.9122 - val_loss: 0.4061 - val_accuracy: 0.8374\n",
      "Epoch 8/15\n",
      "149/149 [==============================] - 57s 383ms/step - loss: 0.2086 - accuracy: 0.9217 - val_loss: 0.3620 - val_accuracy: 0.8454\n",
      "Epoch 9/15\n",
      "149/149 [==============================] - 57s 382ms/step - loss: 0.1975 - accuracy: 0.9236 - val_loss: 0.4742 - val_accuracy: 0.8420\n",
      "Epoch 10/15\n",
      "149/149 [==============================] - 57s 382ms/step - loss: 0.1823 - accuracy: 0.9328 - val_loss: 0.4131 - val_accuracy: 0.8414\n",
      "Epoch 11/15\n",
      "149/149 [==============================] - 58s 391ms/step - loss: 0.1697 - accuracy: 0.9375 - val_loss: 0.4383 - val_accuracy: 0.8373\n",
      "Epoch 12/15\n",
      "149/149 [==============================] - 57s 385ms/step - loss: 0.1586 - accuracy: 0.9421 - val_loss: 0.4258 - val_accuracy: 0.8318\n",
      "Epoch 13/15\n",
      "149/149 [==============================] - 57s 382ms/step - loss: 0.1471 - accuracy: 0.9471 - val_loss: 0.5627 - val_accuracy: 0.8328\n",
      "Epoch 14/15\n",
      "149/149 [==============================] - 57s 380ms/step - loss: 0.1398 - accuracy: 0.9502 - val_loss: 0.4669 - val_accuracy: 0.8359\n",
      "Epoch 15/15\n",
      "149/149 [==============================] - 57s 382ms/step - loss: 0.1285 - accuracy: 0.9536 - val_loss: 0.6109 - val_accuracy: 0.8258\n",
      "149/149 [==============================] - 4s 29ms/step - loss: 0.6109 - accuracy: 0.8258\n",
      "Результат при тестировании: 0.6109138131141663\n",
      "Тестовая точность: 0.825760006904602\n",
      "CPU times: user 29min 2s, sys: 3min 31s, total: 32min 33s\n",
      "Wall time: 15min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_features = 10000\n",
    "\n",
    "# обрезание текстов после данного количества слов (среди top max_features наиболее используемые слова)\n",
    "maxlen = 100\n",
    "batch_size = 168 # увеличьте значение для ускорения обучения\n",
    "from keras.backend import dropout\n",
    "def train_nn_2():\n",
    "    print('Загрузка данных...')\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "    print(len(x_train), 'тренировочные последовательности')\n",
    "    print(len(x_test), 'тестовые последовательности')\n",
    "  \n",
    "    print('Pad последовательности (примеров в x единицу времени)')\n",
    "    x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "    x_test = pad_sequences(x_test, maxlen=maxlen)\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print('x_test shape:', x_test.shape)\n",
    "  \n",
    "    print('Построение модели...')\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 128))\n",
    "    model.add(LSTM(128, dropout=0.5, recurrent_dropout=0.5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(32, activation='LeakyReLU'))\n",
    "    model.add(Dropout(0.45))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(32, activation='LeakyReLU'))            # New line\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(16, activation='LeakyReLU'))\n",
    "    model.add(Dropout(0.3))                                  # New line\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "  \n",
    "    # стоит попробовать использовать другие оптимайзер и другие конфигурации оптимайзеров\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='RMSprop', # при использовании этого оптимайзера модель показывает наилучшие результаты.\n",
    "                  metrics=['accuracy'])\n",
    "    callbacks = [keras.callbacks.ModelCheckpoint(\"fraud_model_at_epoch_{epoch}.h5\")]\n",
    "    print('Процесс обучения...')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=15, # увеличьте при необходимости\n",
    "              callbacks = callbacks,\n",
    "              validation_data=(x_test, y_test))\n",
    "    score, acc = model.evaluate(x_test, y_test,\n",
    "                                batch_size=batch_size)\n",
    "    print('Результат при тестировании:', score)\n",
    "    print('Тестовая точность:', acc)\n",
    "train_nn_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Будем использовать одинаковые функции активации а так же добавим градиентное понижение шага при градиентном спуске"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:47:34.220927Z",
     "iopub.status.busy": "2023-11-22T09:47:34.220166Z",
     "iopub.status.idle": "2023-11-22T10:02:23.828470Z",
     "shell.execute_reply": "2023-11-22T10:02:23.827432Z",
     "shell.execute_reply.started": "2023-11-22T09:47:34.220893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n",
      "25000 тренировочные последовательности\n",
      "25000 тестовые последовательности\n",
      "Pad последовательности (примеров в x единицу времени)\n",
      "x_train shape: (25000, 100)\n",
      "x_test shape: (25000, 100)\n",
      "Построение модели...\n",
      "Процесс обучения...\n",
      "Epoch 1/15\n",
      "149/149 [==============================] - 73s 457ms/step - loss: 0.6875 - accuracy: 0.5386 - val_loss: 0.6440 - val_accuracy: 0.6086\n",
      "Epoch 2/15\n",
      "149/149 [==============================] - 61s 412ms/step - loss: 0.4511 - accuracy: 0.7953 - val_loss: 0.5181 - val_accuracy: 0.7729\n",
      "Epoch 3/15\n",
      "149/149 [==============================] - 59s 393ms/step - loss: 0.3132 - accuracy: 0.8750 - val_loss: 0.3312 - val_accuracy: 0.8574\n",
      "Epoch 4/15\n",
      "149/149 [==============================] - 59s 394ms/step - loss: 0.2466 - accuracy: 0.9070 - val_loss: 0.4377 - val_accuracy: 0.8570\n",
      "Epoch 5/15\n",
      "149/149 [==============================] - 58s 387ms/step - loss: 0.2029 - accuracy: 0.9262 - val_loss: 0.4465 - val_accuracy: 0.8428\n",
      "Epoch 6/15\n",
      "149/149 [==============================] - 57s 384ms/step - loss: 0.1623 - accuracy: 0.9464 - val_loss: 0.4080 - val_accuracy: 0.8460\n",
      "Epoch 7/15\n",
      "149/149 [==============================] - 57s 384ms/step - loss: 0.1285 - accuracy: 0.9575 - val_loss: 0.5423 - val_accuracy: 0.8448\n",
      "Epoch 8/15\n",
      "149/149 [==============================] - 57s 383ms/step - loss: 0.1045 - accuracy: 0.9666 - val_loss: 0.5894 - val_accuracy: 0.8415\n",
      "Epoch 9/15\n",
      "149/149 [==============================] - 58s 390ms/step - loss: 0.0858 - accuracy: 0.9718 - val_loss: 0.6843 - val_accuracy: 0.8404\n",
      "Epoch 10/15\n",
      "149/149 [==============================] - 57s 382ms/step - loss: 0.0712 - accuracy: 0.9771 - val_loss: 0.6514 - val_accuracy: 0.8385\n",
      "Epoch 11/15\n",
      "149/149 [==============================] - 57s 380ms/step - loss: 0.0591 - accuracy: 0.9810 - val_loss: 0.7637 - val_accuracy: 0.8343\n",
      "Epoch 12/15\n",
      "149/149 [==============================] - 57s 379ms/step - loss: 0.0521 - accuracy: 0.9824 - val_loss: 0.8544 - val_accuracy: 0.8336\n",
      "Epoch 13/15\n",
      "149/149 [==============================] - 56s 377ms/step - loss: 0.0447 - accuracy: 0.9862 - val_loss: 0.9536 - val_accuracy: 0.8298\n",
      "Epoch 14/15\n",
      "149/149 [==============================] - 57s 380ms/step - loss: 0.0407 - accuracy: 0.9880 - val_loss: 0.9262 - val_accuracy: 0.8364\n",
      "Epoch 15/15\n",
      "149/149 [==============================] - 57s 385ms/step - loss: 0.0376 - accuracy: 0.9882 - val_loss: 1.1552 - val_accuracy: 0.8301\n",
      "149/149 [==============================] - 4s 28ms/step - loss: 1.1552 - accuracy: 0.8301\n",
      "Результат при тестировании: 1.155226707458496\n",
      "Тестовая точность: 0.830079972743988\n",
      "CPU times: user 28min 47s, sys: 3min 30s, total: 32min 18s\n",
      "Wall time: 14min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_features = 10000\n",
    "\n",
    "# обрезание текстов после данного количества слов (среди top max_features наиболее используемые слова)\n",
    "maxlen = 100\n",
    "batch_size = 168 # увеличьте значение для ускорения обучения\n",
    "from keras.backend import dropout\n",
    "def train_nn_2():\n",
    "    print('Загрузка данных...')\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "    print(len(x_train), 'тренировочные последовательности')\n",
    "    print(len(x_test), 'тестовые последовательности')\n",
    "  \n",
    "    print('Pad последовательности (примеров в x единицу времени)')\n",
    "    x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "    x_test = pad_sequences(x_test, maxlen=maxlen)\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print('x_test shape:', x_test.shape)\n",
    "  \n",
    "    print('Построение модели...')\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 128))\n",
    "    model.add(LSTM(128, dropout=0.5, recurrent_dropout=0.5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(32, activation='LeakyReLU'))\n",
    "    model.add(Dropout(0.45))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(32, activation='LeakyReLU'))            # New line\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(16, activation='LeakyReLU'))\n",
    "    model.add(Dropout(0.4))                                  # New line\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=1e-2,\n",
    "        decay_steps=10000,\n",
    "        decay_rate=0.9)\n",
    "    optimizer = keras.optimizers.RMSprop(learning_rate=lr_schedule)\n",
    "  \n",
    "    # стоит попробовать использовать другие оптимайзер и другие конфигурации оптимайзеров\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer= optimizer,\n",
    "                  metrics=['accuracy']) \n",
    "    callbacks = [keras.callbacks.ModelCheckpoint(\"fraud_model_at_epoch_{epoch}.h5\")]\n",
    "    print('Процесс обучения...')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=15, # увеличьте при необходимости\n",
    "              callbacks = callbacks,\n",
    "              validation_data=(x_test, y_test))\n",
    "    score, acc = model.evaluate(x_test, y_test,\n",
    "                                batch_size=batch_size)\n",
    "    print('Результат при тестировании:', score)\n",
    "    print('Тестовая точность:', acc)\n",
    "train_nn_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшим количество эпох до 4 на 4 жпохе как видим результат обучения только ухудшается"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T10:05:25.005250Z",
     "iopub.status.busy": "2023-11-22T10:05:25.004228Z",
     "iopub.status.idle": "2023-11-22T10:10:26.563544Z",
     "shell.execute_reply": "2023-11-22T10:10:26.562586Z",
     "shell.execute_reply.started": "2023-11-22T10:05:25.005200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n",
      "25000 тренировочные последовательности\n",
      "25000 тестовые последовательности\n",
      "Pad последовательности (примеров в x единицу времени)\n",
      "x_train shape: (25000, 100)\n",
      "x_test shape: (25000, 100)\n",
      "Построение модели...\n",
      "Процесс обучения...\n",
      "Epoch 1/5\n",
      "139/139 [==============================] - 69s 459ms/step - loss: 0.7122 - accuracy: 0.4990 - val_loss: 0.6941 - val_accuracy: 0.4996\n",
      "Epoch 2/5\n",
      "139/139 [==============================] - 57s 413ms/step - loss: 0.6657 - accuracy: 0.5733 - val_loss: 1.2658 - val_accuracy: 0.5032\n",
      "Epoch 3/5\n",
      "139/139 [==============================] - 56s 403ms/step - loss: 0.4996 - accuracy: 0.7616 - val_loss: 0.3609 - val_accuracy: 0.8384\n",
      "Epoch 4/5\n",
      "139/139 [==============================] - 55s 396ms/step - loss: 0.3276 - accuracy: 0.8692 - val_loss: 0.3814 - val_accuracy: 0.8512\n",
      "Epoch 5/5\n",
      "139/139 [==============================] - 55s 392ms/step - loss: 0.2585 - accuracy: 0.9016 - val_loss: 0.4646 - val_accuracy: 0.8406\n",
      "139/139 [==============================] - 4s 27ms/step - loss: 0.4646 - accuracy: 0.8406\n",
      "Результат при тестировании: 0.4645598530769348\n",
      "Тестовая точность: 0.8406400084495544\n",
      "CPU times: user 9min 23s, sys: 1min 6s, total: 10min 30s\n",
      "Wall time: 5min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_features = 10000\n",
    "\n",
    "# обрезание текстов после данного количества слов (среди top max_features наиболее используемые слова)\n",
    "maxlen = 100\n",
    "batch_size = 180 # увеличьте значение для ускорения обучения\n",
    "from keras.backend import dropout\n",
    "def train_nn_3():\n",
    "    print('Загрузка данных...')\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "    print(len(x_train), 'тренировочные последовательности')\n",
    "    print(len(x_test), 'тестовые последовательности')\n",
    "  \n",
    "    print('Pad последовательности (примеров в x единицу времени)')\n",
    "    x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "    x_test = pad_sequences(x_test, maxlen=maxlen)\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print('x_test shape:', x_test.shape)\n",
    "  \n",
    "    print('Построение модели...')\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 128))\n",
    "    model.add(LSTM(128, dropout=0.5, recurrent_dropout=0.5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(32, activation='LeakyReLU'))\n",
    "    model.add(Dropout(0.45))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(32, activation='LeakyReLU'))            # New line\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(16, activation='LeakyReLU'))\n",
    "    model.add(Dropout(0.4))                                  # New line\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=1e-2,\n",
    "        decay_steps=10000,\n",
    "        decay_rate=0.9)\n",
    "    optimizer = keras.optimizers.RMSprop(learning_rate=lr_schedule)\n",
    "  \n",
    "    # стоит попробовать использовать другие оптимайзер и другие конфигурации оптимайзеров\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer= optimizer,\n",
    "                  metrics=['accuracy']) \n",
    "    callbacks = [keras.callbacks.ModelCheckpoint(\"fraud_model_at_epoch_{epoch}.h5\")]\n",
    "    print('Процесс обучения...')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=5, # увеличьте при необходимости\n",
    "              callbacks = callbacks,\n",
    "              validation_data=(x_test, y_test))\n",
    "    score, acc = model.evaluate(x_test, y_test,\n",
    "                                batch_size=batch_size)\n",
    "    print('Результат при тестировании:', score)\n",
    "    print('Тестовая точность:', acc)\n",
    "train_nn_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итог\n",
    "Как видим уменьшение эпох позволило улучшить точность на валидационной выборке при дальнейшем обучении модель переобучается. Еще большей процент dropout не решает проблему увеличение бача тоже не особо помогает скорей всего данное состояние является хорошим локальным минимумумом."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
