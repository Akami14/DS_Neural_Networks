{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1\nПопробуйте улучшить точность распознавания образов cifar 10 сверточной нейронной сетью, рассмотренной на уроке. Приложите анализ с описанием того, что улучшает работу нейронной сети, а что ухудшает  \n# 2\nОпишите в анализе, какие изменения необходимо было бы внести в получившуюся нейронную сеть, если бы ей нужно было работать не с cifar10, а с MNIST, CIFAR100 и IMAGENET","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# 2\nС MNIST будет неплохо работа и та архитектура что и у cifar Предположительно можно будет упростить архитиктуру и уменьшить количество слоев. input 28, 28 a output одинаков. В случае использования уже готовых архитектур необходимо добавить 1 простраснство в данные для признаков.  \nC CIFAR100  потребуется больше слоев свертки так же поменяется форма output будет 100  \nС IMAGENET скорей всего потребуется еще больше слоев свертки так же меняется форма ввода  469x387 или исользуя препроцесинг и понижение размерности\nВ модели хорошой идее будет добавить бач нормализацию что бы лос не становлся неопределенным","metadata":{}},{"cell_type":"code","source":"#2\nС MNIST будет неплохо работа и та архитектура что и у cifar Предположительно можно будет упростить архитиктуру и уменьшить количество слоев. input 28, 28 a output одинаков. В случае использования уже готовых архитектур необходимо добавить 1 простраснство в данные для признаков.  \nC CIFAR100  потребуется больше слоев свертки так же поменяется форма инпута в оутпуте будет 100  \nС IMAGENET скорей всего потребуется еще больше слоев свертки так же меняется форма ввода  469x387 или исользуя препроцесинг и понижение размерности\nВ модели хорошой идее будет добавить бач нормализацию что бы лос не становлся неопределенным","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Вариант по умолчанию","metadata":{}},{"cell_type":"code","source":"from __future__ import print_function\nimport keras\n\nfrom keras.applications import ResNet50\nfrom keras.applications import ResNet152\nfrom keras.applications import VGG19\n\nfrom keras.datasets import cifar10\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense, GlobalAveragePooling2D\nimport os\n\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255\n\ndatagen = ImageDataGenerator(\n        rotation_range=10,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=False,\n        vertical_flip=False)\n\n# Установка параметров нейросети\nbatch_size = 32\nnum_classes = 10\nepochs = 1\n\ntrain_generator = datagen.flow(x_train, y_train, batch_size=batch_size)\ntest_generator = datagen.flow(x_test, y_test, batch_size=batch_size)\n\n# Создание предварительно обученной модели ResNet50\nbase_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n\n# Создание модели для Featurization\nmodel = Sequential()\nmodel.add(base_model)\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dense(num_classes, activation='softmax'))\n\n# Компиляция модели\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\n# Обучение модели\nmodel.fit(train_generator,\n                    steps_per_epoch=len(x_train) // batch_size,\n                    epochs=epochs,\n                    validation_data=test_generator,\n                    validation_steps=len(x_test) // batch_size)\n\n# Оценка производительности модели на тестовых данных\nscore = model.evaluate(test_generator, steps=len(x_test) // batch_size)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","metadata":{"execution":{"iopub.status.busy":"2023-11-21T09:13:58.048781Z","iopub.execute_input":"2023-11-21T09:13:58.049601Z","iopub.status.idle":"2023-11-21T09:16:02.266994Z","shell.execute_reply.started":"2023-11-21T09:13:58.049562Z","shell.execute_reply":"2023-11-21T09:16:02.266006Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"1562/1562 [==============================] - 113s 49ms/step - loss: 155.5799 - accuracy: 0.0070 - val_loss: 168.2682 - val_accuracy: 0.0000e+00\n312/312 [==============================] - 8s 24ms/step - loss: 168.6040 - accuracy: 0.0000e+00\nTest loss: 168.60403442382812\nTest accuracy: 0.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Очевидно что нехватает эпох обучения а так же использовать ImageDataGenerator лучше после того как определимся с базовой архитекторуй. Ниже посмотрим 3 архитиктуры на 3 эпохах (орграничение связаное с мощностями)","metadata":{}},{"cell_type":"code","source":"from __future__ import print_function\nimport keras\n\nfrom keras.applications import ResNet50\nfrom keras.applications import ResNet152\nfrom keras.applications import VGG19\n\nfrom keras.datasets import cifar10\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense, GlobalAveragePooling2D\nimport os\nfrom keras import models, layers\nimport keras\nfrom keras.utils import to_categorical\n","metadata":{"execution":{"iopub.status.busy":"2023-11-21T07:55:19.790445Z","iopub.execute_input":"2023-11-21T07:55:19.790836Z","iopub.status.idle":"2023-11-21T07:55:20.907771Z","shell.execute_reply.started":"2023-11-21T07:55:19.790806Z","shell.execute_reply":"2023-11-21T07:55:20.906812Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"(x_train, y_train), (x_test, y_test) = cifar10.load_data()\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255\n# Установка параметров нейросети\nbatch_size = 14\nnum_classes = 10\nepochs = 3\ny_test = to_categorical(y_test)\ny_train = to_categorical(y_train)\n\n\n# Создание предварительно обученной модели ResNet50\nbase_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n\n# Создание модели для Featurization\nmodel = Sequential()\nmodel.add(base_model)\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dense(num_classes, activation='softmax'))\n\n# Компиляция модели\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\n# Обучение модели\nmodel.fit(x=x_train, y=y_train, batch_size=batch_size,\n                    epochs=epochs,\n                    validation_data=(x_test, y_test))\n\n# Оценка производительности модели на тестовых данных\nscore = model.evaluate(x_test, y_test)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","metadata":{"execution":{"iopub.status.busy":"2023-11-21T08:12:26.124640Z","iopub.execute_input":"2023-11-21T08:12:26.125029Z","iopub.status.idle":"2023-11-21T08:20:05.502053Z","shell.execute_reply.started":"2023-11-21T08:12:26.124996Z","shell.execute_reply":"2023-11-21T08:20:05.500980Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Epoch 1/3\n3572/3572 [==============================] - 174s 39ms/step - loss: 2.4125 - accuracy: 0.2170 - val_loss: 2.3145 - val_accuracy: 0.2336\nEpoch 2/3\n3572/3572 [==============================] - 138s 39ms/step - loss: 2.1624 - accuracy: 0.2548 - val_loss: 1.6757 - val_accuracy: 0.3674\nEpoch 3/3\n3572/3572 [==============================] - 138s 39ms/step - loss: 1.5993 - accuracy: 0.4099 - val_loss: 1.4503 - val_accuracy: 0.4738\n313/313 [==============================] - 4s 11ms/step - loss: 1.4503 - accuracy: 0.4738\nTest loss: 1.450250506401062\nTest accuracy: 0.47380000352859497\n","output_type":"stream"}]},{"cell_type":"code","source":"(x_train, y_train), (x_test, y_test) = cifar10.load_data()\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255\n# Установка параметров нейросети\nbatch_size = 14\nnum_classes = 10\nepochs = 3\ny_test = to_categorical(y_test)\ny_train = to_categorical(y_train)\n\n\n# Создание предварительно обученной модели ResNet50\nbase_model = ResNet152(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n\n# Создание модели для Featurization\nmodel = Sequential()\nmodel.add(base_model)\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dense(num_classes, activation='softmax'))\n\n# Компиляция модели\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\n# Обучение модели\nmodel.fit(x=x_train, y=y_train, batch_size=batch_size,\n                    epochs=epochs,\n                    validation_data=(x_test, y_test))\n\n# Оценка производительности модели на тестовых данных\nscore = model.evaluate(x_test, y_test)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","metadata":{"execution":{"iopub.status.busy":"2023-11-21T08:21:04.734849Z","iopub.execute_input":"2023-11-21T08:21:04.735258Z","iopub.status.idle":"2023-11-21T08:43:20.716705Z","shell.execute_reply.started":"2023-11-21T08:21:04.735225Z","shell.execute_reply":"2023-11-21T08:43:20.715701Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152_weights_tf_dim_ordering_tf_kernels_notop.h5\n234698864/234698864 [==============================] - 2s 0us/step\nEpoch 1/3\n3572/3572 [==============================] - 515s 114ms/step - loss: 2.5767 - accuracy: 0.1291 - val_loss: 2.3741 - val_accuracy: 0.1001\nEpoch 2/3\n3572/3572 [==============================] - 401s 112ms/step - loss: 2.4313 - accuracy: 0.1405 - val_loss: 2.1011 - val_accuracy: 0.1629\nEpoch 3/3\n3572/3572 [==============================] - 400s 112ms/step - loss: 2.0734 - accuracy: 0.2143 - val_loss: 2.0760 - val_accuracy: 0.2247\n313/313 [==============================] - 8s 25ms/step - loss: 2.0760 - accuracy: 0.2247\nTest loss: 2.076000213623047\nTest accuracy: 0.22470000386238098\n","output_type":"stream"}]},{"cell_type":"code","source":"(x_train, y_train), (x_test, y_test) = cifar10.load_data()\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255\n# Установка параметров нейросети\nbatch_size = 14\nnum_classes = 10\nepochs = 3\ny_test = to_categorical(y_test)\ny_train = to_categorical(y_train)\n\n# Создание предварительно обученной модели ResNet50\nbase_model = VGG19(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n\n# Создание модели для Featurization\nmodel = Sequential()\nmodel.add(base_model)\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dense(num_classes, activation='softmax'))\n\n# Компиляция модели\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\n# Обучение модели\nmodel.fit(x=x_train, y=y_train, batch_size=batch_size,\n                    epochs=epochs,\n                    validation_data=(x_test, y_test))\n\n# Оценка производительности модели на тестовых данных\nscore = model.evaluate(x_test, y_test)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","metadata":{"execution":{"iopub.status.busy":"2023-11-21T08:57:01.505363Z","iopub.execute_input":"2023-11-21T08:57:01.505812Z","iopub.status.idle":"2023-11-21T09:02:32.640128Z","shell.execute_reply.started":"2023-11-21T08:57:01.505777Z","shell.execute_reply":"2023-11-21T09:02:32.638999Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n80134624/80134624 [==============================] - 1s 0us/step\nEpoch 1/3\n3572/3572 [==============================] - 113s 30ms/step - loss: 2.3223 - accuracy: 0.1007 - val_loss: 2.3038 - val_accuracy: 0.1000\nEpoch 2/3\n3572/3572 [==============================] - 105s 29ms/step - loss: 2.3036 - accuracy: 0.0985 - val_loss: 2.3026 - val_accuracy: 0.1000\nEpoch 3/3\n3572/3572 [==============================] - 105s 29ms/step - loss: 2.3029 - accuracy: 0.0992 - val_loss: 2.3026 - val_accuracy: 0.1000\n313/313 [==============================] - 4s 11ms/step - loss: 2.3026 - accuracy: 0.1000\nTest loss: 2.3026206493377686\nTest accuracy: 0.10000000149011612\n","output_type":"stream"}]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-21T09:04:34.194775Z","iopub.execute_input":"2023-11-21T09:04:34.195139Z","iopub.status.idle":"2023-11-21T09:04:34.215991Z","shell.execute_reply.started":"2023-11-21T09:04:34.195109Z","shell.execute_reply":"2023-11-21T09:04:34.215178Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Model: \"sequential_5\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n vgg19 (Functional)          (None, 1, 1, 512)         20024384  \n                                                                 \n global_average_pooling2d_5  (None, 512)               0         \n  (GlobalAveragePooling2D)                                       \n                                                                 \n dense_5 (Dense)             (None, 10)                5130      \n                                                                 \n=================================================================\nTotal params: 20029514 (76.41 MB)\nTrainable params: 20029514 (76.41 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### ResNet50 быстрее спускается к оптимуму в отличее от других архитектур","metadata":{}},{"cell_type":"markdown","source":"# Более компактный вариант записи ","metadata":{}},{"cell_type":"code","source":"base_model1 = VGG19(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\nbase_model2 = ResNet152(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\nbase_model3 = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\nb_model_list = [base_model1, base_model2, base_model3]\nnames = ['VGG19','ResNet152', 'ResNet50']\nfor base_model, name in (models, name):\n    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n    x_train = x_train.astype('float32')\n    x_test = x_test.astype('float32')\n    x_train /= 255\n    x_test /= 255\n    # Установка параметров нейросети\n    batch_size = 14\n    num_classes = 10\n    epochs = 3\n    y_test = to_categorical(y_test)\n    y_train = to_categorical(y_train)\n\n    # Создание модели для Featurization\n    model = Sequential()\n    model.add(base_model)\n    model.add(GlobalAveragePooling2D())\n    model.add(Dense(num_classes, activation='softmax'))\n\n    # Компиляция модели\n    model.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\n    # Обучение модели\n    model.fit(x=x_train, y=y_train, batch_size=batch_size,\n                    epochs=epochs,\n                    validation_data=(x_test, y_test))\n\n    # Оценка производительности модели на тестовых данных\n    score = model.evaluate(x_test, y_test)\n    print('name')\n    model.summary()\n    print('Test loss:', score[0])\n    print('Test accuracy:', score[1])\n        ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Своя архитектура","metadata":{}},{"cell_type":"code","source":"from keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout\n# Set the neural network parameters\nbatch_size = 20\nnum_classes = 10\nepochs = 3\ndata_augmentation = True\nnum_predictions = 20\nsave_dir = os.path.join(os.getcwd(), 'saved_models')\nmodel_name = 'keras_model.h5'\n\n# Load dataset\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255\n\ny_test = to_categorical(y_test)\ny_train = to_categorical(y_train)\n\nprint('x_train shape:', x_train.shape)\nprint(x_train.shape[0], 'training examples')\nprint(x_test.shape[0], 'testing examples')\n\n\n# Define the model architecture\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", input_shape=(32, 32, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", input_shape=(32, 32, 3)))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Dropout(0.1))\n\nmodel.add(Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\"))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\"))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Dropout(0.3))\n\n#model.add(Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\"))\n#model.add(MaxPooling2D((2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation=\"relu\"))\n#model.add(Dense(128, activation=\"relu\"))\nmodel.add(Dense(10, activation=\"softmax\"))\n\nmodel.summary()\n# Компиляция модели\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\n# Обучение модели\nmodel.fit(x=x_train, y=y_train, batch_size=batch_size,\n                    epochs=epochs,\n                    validation_data=(x_test, y_test))\n\n# Оценка производительности модели на тестовых данных\nscore = model.evaluate(x_test, y_test)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","metadata":{"execution":{"iopub.status.busy":"2023-11-21T09:10:23.115376Z","iopub.execute_input":"2023-11-21T09:10:23.116152Z","iopub.status.idle":"2023-11-21T09:11:21.868997Z","shell.execute_reply.started":"2023-11-21T09:10:23.116114Z","shell.execute_reply":"2023-11-21T09:11:21.868085Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"x_train shape: (50000, 32, 32, 3)\n50000 training examples\n10000 testing examples\nModel: \"sequential_8\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_1 (Conv2D)           (None, 32, 32, 32)        896       \n                                                                 \n batch_normalization (Batch  (None, 32, 32, 32)        128       \n Normalization)                                                  \n                                                                 \n conv2d_2 (Conv2D)           (None, 32, 32, 32)        9248      \n                                                                 \n max_pooling2d (MaxPooling2  (None, 16, 16, 32)        0         \n D)                                                              \n                                                                 \n dropout (Dropout)           (None, 16, 16, 32)        0         \n                                                                 \n conv2d_3 (Conv2D)           (None, 16, 16, 64)        18496     \n                                                                 \n batch_normalization_1 (Bat  (None, 16, 16, 64)        256       \n chNormalization)                                                \n                                                                 \n conv2d_4 (Conv2D)           (None, 16, 16, 64)        36928     \n                                                                 \n max_pooling2d_1 (MaxPoolin  (None, 8, 8, 64)          0         \n g2D)                                                            \n                                                                 \n dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n                                                                 \n conv2d_5 (Conv2D)           (None, 8, 8, 128)         73856     \n                                                                 \n batch_normalization_2 (Bat  (None, 8, 8, 128)         512       \n chNormalization)                                                \n                                                                 \n conv2d_6 (Conv2D)           (None, 8, 8, 128)         147584    \n                                                                 \n max_pooling2d_2 (MaxPoolin  (None, 4, 4, 128)         0         \n g2D)                                                            \n                                                                 \n dropout_2 (Dropout)         (None, 4, 4, 128)         0         \n                                                                 \n flatten (Flatten)           (None, 2048)              0         \n                                                                 \n dense_6 (Dense)             (None, 256)               524544    \n                                                                 \n dense_7 (Dense)             (None, 10)                2570      \n                                                                 \n=================================================================\nTotal params: 815018 (3.11 MB)\nTrainable params: 814570 (3.11 MB)\nNon-trainable params: 448 (1.75 KB)\n_________________________________________________________________\nEpoch 1/3\n","output_type":"stream"},{"name":"stderr","text":"2023-11-21 09:10:27.512137: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_8/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"2500/2500 [==============================] - 21s 7ms/step - loss: 1.3276 - accuracy: 0.5206 - val_loss: 1.1444 - val_accuracy: 0.6000\nEpoch 2/3\n2500/2500 [==============================] - 16s 7ms/step - loss: 0.9002 - accuracy: 0.6841 - val_loss: 0.8839 - val_accuracy: 0.6954\nEpoch 3/3\n2500/2500 [==============================] - 16s 6ms/step - loss: 0.7552 - accuracy: 0.7368 - val_loss: 0.7625 - val_accuracy: 0.7370\n313/313 [==============================] - 1s 4ms/step - loss: 0.7625 - accuracy: 0.7370\nTest loss: 0.7625251412391663\nTest accuracy: 0.7369999885559082\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### При большем количестве эпох удалось бы добится большей точности.","metadata":{}}]}